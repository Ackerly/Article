# 深入浅出音视频与 WebRTC
## 常见的音视频网络通信协议
### 普通直播协议  
这类直播对实时性要求不那么高，使用CDN进行内容分发，会有几秒甚至十几秒的延时，主要关注画面质量、音视频是卡顿等问题，一般选用 RTMP 和 HLS 协议  
**基本概念**  
_RTMP_  
RTMP （Real Time Messaging Protocol），即“实时消息传输协议”， 它实际上并不能做到真正的实时，一般情况最少都会有几秒到几十秒的延迟，是 Adobe 公司开发的音视频数据传输的实时消息传送协议，RTMP 协议基于 TCP，包括 RTMP 基本协议及 RTMPT/RTMPS/RTMPE 等多种变种，RTMP 是目前主流的流媒体传输协议之一，对CDN支持良好，实现难度较低，是大多数直播平台的选择，不过RTMP有一个最大的不足 —— 不支持浏览器，且苹果 ios 不支持，Adobe 已停止对其更新  
_HLS_  
HLS （Http Live Streaming）是由苹果公司定义的基于 HTTP 的流媒体实时传输协议，被广泛的应用于视频点播和直播领域，HLS 规范规定播放器至少下载一个 ts 切片才能播放，所以 HLS 理论上至少会有一个切片的延迟  
HLS 在移动端兼容性比较好，ios就不用说了，Android现在也基本都支持 HLS 协议了，pc端如果要使用可以使用 hls.js 适配器  
> HLS 的原理是将整个流分为多个小的文件来下载，每次只下载若干个，服务器端会将最新的直播数据生成新的小文件，当客户端获取直播时，它通过获取最新的视频文件片段来播放，从而保证用户在任何时候连接进来时都会看到较新的内容，实现近似直播的体验；HLS 的延迟一般会高于普通的流媒体直播协议，传输内容包括两部分：一部分 M3U8 是索引文件，另一部分是 TS 文件，用来存储音视频的媒体信息

_RTMP 和 HLS 如何选择_  
- 流媒体推流，一般使用 RTMP 协议
- 移动端的网页播放器最好使用 HLS 协议，RTMP 不支持浏览器
- iOS 要使用 HLS 协议，因为不支持 RTMP 协议
- 点播系统最好使用 HLS 协议，因为点播没有实时互动需求，延迟大一些是可以接受的，并且可以在浏览器上直接观看

**普通直播基本架构**  
由直播 客户端 、 信令 服务器和 CDN 网络这三部分组成  
直播 客户端主要包括音视频数据的采集、编码、推流、拉流、解码与播放功能，但实际上这些功能并不是在同一个客户端中实现的，为什么呢？因为作为主播来说，他不需要看到观众的视频或听到观众的声音，而作为观众来讲，他们与主播之间是通过文字进行交流的，不需要向主播分享自己的音视频信息  
对于主播客户端来说，它可以设备的摄像头、麦克风采集数据，然后对采集到的音视频数据进行编码，最后将编码后的音视频数据推送给 CDN  
对于观众客户端来说，它首先需要获取到主播房间的流媒体地址，观众进入房间后从 CDN 拉取音视频数据，并对获取到的音视频数据进行解码，最后进行音视频的渲染与播放  
信令服务器，主要用于接收信令，并根据信令处理一些和业务相关的逻辑，如创建房间、加入房间、离开房间、文字聊天等  
CDN 网络，主要用于媒体数据的分发，传给它的媒体数据可以很快传送给各地的用户  

### 实时直播协议
WebRTC（Web Real-Time Communication），即“网页即时通信”，WebRTC 是一个支持浏览器进行实时语音、视频对话的开源协议，目前主流浏览器都支持WebRTC，即便在网络信号一般的情况下也具备较好的稳定性，WebRTC 可以实现点对点通信，通信双方延时低，使用户无需下载安装任何插件就可以进行实时通信  
在WebRTC发布之前，开发实时音视频交互应用的成本很高，需要考虑的技术问题很多，如音视频的编解码问题，数据传输问题，延时、丢包、抖动、回音的处理和消除等，如果要兼容浏览器端的实时音视频通信，还需要额外安装插件， WebRTC 大大降低了音视频开发的门槛，开发者只需要调用 WebRTC API 即可快速构建出音视频应用  

## 音视频设备检测
### 设备的基本原理
**音频设备**  
音频输入设备的主要工作是采集音频数据，而采集音频数据的本质就是模数转换（A/D），即将模似信号转换成数字信号，采集到的数据再经过量化、编码，最终形成数字信号，这就是音频设备所要完成的工作  
**视频设备**  
视频设备，与音频输入设备很类似，视频设备的模数转换（A/D）模块即光学传感器， 将光转换成数字信号，即 RGB（Red、Green、Blue）数据，获得 RGB 数据后，还要通过 DSP（Digital Signal Processer）进行优化处理，如自动增强、色彩饱和等都属于这一阶段要做的事情，通过 DSP 优化处理后获得 RGB 图像，然后进行压缩、传输，而编码器一般使用的输入格式为 YUV，所以在摄像头内部还有一个专门的模块用于将 RGB 图像转为 YUV 格式的图像  
YUV 也是一种色彩编码方法，它将亮度信息（Y）与色彩信息（UV）分离，即使没有 UV 信息一样可以显示完整的图像，只不过是黑白的，这样的设计很好地解决了彩色电视机与黑白电视的兼容问题（这也是 YUV 设计的初衷）相对于 RGB 颜色空间，YUV 的目的是为了编码、传输的方便，减少带宽占用和信息出错，人眼的视觉特点是对亮度更敏感，对位置、色彩相对来说不敏感，在视频编码系统中为了降低带宽，可以保存更多的亮度信息，保存较少的色差信息  

### 获取音视频设备列表

原文:  
[深入浅出音视频与 WebRTC](https://mp.weixin.qq.com/s/yVnEnA1IhVde1OiNlGKN-w)
